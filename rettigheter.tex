Så kanskje det ikke er så lenge til en AI blir selvbevist. Eller, som nevnt tidligere, hva hvis man kan overføre menneskets minne til en datamaskin.

Allerede idag har vi biler som kjører av seg selv og kun trenger en
menneskelig sjåfør for å tilfredstille eksisterende lover. Men det er ikke
utenkelig at det innen kort tid vil være lov for en bil å kjøre helt alene. Så la oss tenke oss at det finnes biler som kan gjøre nettopp det På vei hjem fra
jobben har du kommet over noe du vil kjøpe, men som du ikke får med deg på
toget. Da kan du starte en applikasjon på telefonen, og be bilen din komme og hente deg.

Men på veien kommer bilen ut for en ulykke og ender med å ta liv av en person.
Hvem er det som har annsvaret? Kanskje er det deg som eier av bilen, men du
kunne aldri forutsett hva som kom til å skje på turen. Kanskje er er
selskapet som produserte bilen, burde de ha forutsett hva som kom til å skje? Eller vil det kanskje være som sitter med alt ansvaret?

Selv om det i dag mest sansynlig ville vært selskapet eller eierens skyld, så er det tenkelig at det i fremtiden vil komme AI-er som vil lære ting på egenhånd
og selskapet ikke lengre har kontroll over hva den gjør.

Tenk deg en robot som tar førerprøven og består på samme måte som vi mennesker.

På et eller annet tidspunkt må vi innse at en AI har blitt et eget individ med
egen vilje, egne rettigheter og eget ansvar. 


Når AI-er har blitt beviste og fått samme rettigheter som mennesker - hva da
med alle industriroboter osv. Er det etisk akseptabelt å lage AI-er som er for
<<dumme>> til å være selvbeviste?
Det er jo kanskje mer praktisk med intelligente industriroboter så kanskje man
lager AI-er som er intelligente nok til å være selvbeviste, men vi legger inn en
sperre for at den skal gjøre som vi vil. Hva hvis man praktiserer det samme på
mennesker? Lager mennesker med medfødte hjerneskader som kan brukes i industri
og minerydding?


Kanskje blir det å lage en AI i fremtiden mye av det samme som å bli forelder.
Dersom man skal lage en AI må man gjøre det man kan for at AI-en skal følge
lover og regler, og dersom man ikke gjør det, ikke får lov til å lage AI-en.
Etter dette vil det være de individuelle AI-ene som selv har annsvaret og
skaperene kun kan få skylden dersom AI-en er under ett visst stadie i utviklingsprosessen.
